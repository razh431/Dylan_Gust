{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "1. Add a way to get new text when a website is added \n",
    "1a. A way to find the difference between new text or old text. \n",
    "        - use the hexdigest\n",
    "2. A way to store the text \n",
    "        - use another dictionary\n",
    "3. A way to append the text and the links to the email. \n",
    "4. A way to download files from a file and attach it to the email. \n",
    "5. A way to process the new links (go to link and grab the text/ grab potential documents, or if it is a documetn\n",
    "    it will send to the recipient. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Monitor():\n",
    "\n",
    "    #recipient_email = 'dan@turbinehub.com'\n",
    "    #password = 'fugquz-sohne0-Nigmyw'\n",
    "    password = 'pxkqlllkkwgwfszm'\n",
    "    #sender_email = 'dylan@turbinehub.com'\n",
    "    sender_email = 'dan@turbinehub.com'\n",
    "    recipient_email = 'dylan@turbinehub.com'\n",
    "    #will recieve a url as a key, and a hash as a value\n",
    "    previous_hash = dict()\n",
    "    #will recieve a url as a key and a list of links as a value\n",
    "    previous_links = dict()\n",
    "    new_links = list()\n",
    "    base_link = ''\n",
    "    url_list = list()\n",
    "    text_list = dict()\n",
    "\n",
    "    def __init__(self,url_list, base_link):\n",
    "        self.url_list = url_list\n",
    "        self.base_link = base_link\n",
    "\n",
    "\n",
    "    def send_email(self, url=None, diff_text=None):\n",
    "        body = 'There is a change on ' + self.base_link + '\\n'\n",
    "        if url:\n",
    "            for link in url:\n",
    "                if 'www' in link or 'http' in link:\n",
    "                    body += link + '\\n'\n",
    "                else:\n",
    "                    body += self.base_link + link + ' \\n'\n",
    "            body += 'If there is no URL, then there is a change to the text'\n",
    "        else:\n",
    "            body += 'There is no new links to this change. Please check the website'\n",
    "\n",
    "        if diff_text:\n",
    "            body += diff_text\n",
    "\n",
    "        message = MIMEText(body, 'plain')\n",
    "        message['From'] = self.sender_email\n",
    "        message['To'] = self.recipient_email\n",
    "        message['Subject'] = 'URGENT!!! NEW CHANGE DETECTED'\n",
    "        #this will create a new session\n",
    "        session = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        session.starttls()\n",
    "        session.login(self.sender_email, self.password)\n",
    "        text = message.as_string()\n",
    "        session.sendmail(self.sender_email, self.recipient_email , text)\n",
    "\n",
    "    def detect_change(self):\n",
    "        while True:\n",
    "            print(self.url_list)\n",
    "            for url in self.url_list:\n",
    "                    request_url = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                    response = urlopen(request_url).read()\n",
    "                    current_hash = hashlib.sha224(response).hexdigest()\n",
    "                    soup = BeautifulSoup(response, 'lxml')\n",
    "                    text_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                    text_soup = text_soup.get_text(' ', strip=True)\n",
    "                    all_links = self.get_links(soup)\n",
    "                    if url not in self.previous_hash:\n",
    "                        print('adding previous hash')\n",
    "                        self.previous_links[url] = all_links\n",
    "                        self.previous_hash[url] = current_hash\n",
    "                        self.text_list[url] = text_soup\n",
    "                    elif current_hash != self.previous_hash.get(url):\n",
    "                        print('Change detected')\n",
    "                        diff = self.find_differences(all_links, url)\n",
    "                        diff_text = set(self.text_list[url]).difference(text_soup)\n",
    "                        self.send_email(diff, url, diff_text)\n",
    "                        self.previous_links[url] = all_links\n",
    "                        self.previous_hash[url] = current_hash\n",
    "                    else:\n",
    "                        print('No changes found for ' + url)\n",
    "\n",
    "\n",
    "    def find_differences(self, new_links, url):\n",
    "        diff = new_links.difference(self.previous_links[url])\n",
    "        return diff\n",
    "\n",
    "    def get_links(self, soup):\n",
    "        links = set()\n",
    "        for link in soup.findAll('a'):\n",
    "            links.add(link.get('href'))\n",
    "        print(links)\n",
    "        return links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
